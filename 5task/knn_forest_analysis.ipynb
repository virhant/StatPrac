{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7a6ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка данных\n",
    "url = 'https://drive.google.com/uc?export=download&id=1hkgqZ9Dx-3KT88y5ZB3iHhsHnkj2EIK0'\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Делим на признаки и метки\n",
    "labels = df[df.columns[-1]].values\n",
    "feature_matrix = df[df.columns[:-1]].values\n",
    "\n",
    "# Разбиваем на обучающую и тестовую выборки\n",
    "train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split(\n",
    "    feature_matrix, labels, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовая модель k-NN\n",
    "clf = KNeighborsClassifier(n_neighbors=5, metric='l1', weights='distance')\n",
    "clf.fit(train_feature_matrix, train_labels)\n",
    "preds = clf.predict(test_feature_matrix)\n",
    "print(\"Initial accuracy:\", accuracy_score(test_labels, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa719e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подбор гиперпараметров\n",
    "params = {\n",
    "    'n_neighbors': np.arange(1, 11),\n",
    "    'metric': ['manhattan', 'euclidean'],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "}\n",
    "clf_grid = GridSearchCV(clf, params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "clf_grid.fit(train_feature_matrix, train_labels)\n",
    "\n",
    "# Предсказания после настройки\n",
    "preds = clf.predict(test_feature_matrix)\n",
    "print(\"Accuracy after GridSearch (old clf):\", accuracy_score(test_labels, preds))\n",
    "\n",
    "print(\"Best parameters:\", clf_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36dc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучение оптимальной модели\n",
    "optimal_clf = KNeighborsClassifier(**clf_grid.best_params_)\n",
    "optimal_clf.fit(train_feature_matrix, train_labels)\n",
    "pred_prob = optimal_clf.predict_proba(test_feature_matrix)\n",
    "preds = optimal_clf.predict(test_feature_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecdb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравнение распределений вероятностей\n",
    "unique, freq = np.unique(test_labels, return_counts=True)\n",
    "freq = list(map(lambda x: x / len(test_labels), freq))\n",
    "pred_freq = pred_prob.mean(axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\n",
    "plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\n",
    "plt.ylim(0, 0.54)\n",
    "plt.legend()\n",
    "plt.title(\"Class frequency: Predicted vs Real\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa11f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-кривые и AUC-ROC\n",
    "roc_scores = []\n",
    "for i in range(7):\n",
    "    roc = roc_curve(test_labels, pred_prob[:, i], pos_label=i+1)\n",
    "    roc_scores.append(roc_auc_score(test_labels == i+1, pred_prob[:, i]))\n",
    "    plt.plot(roc[0], roc[1], label=f'ROC(label={i+1})')\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"ROC Curves by Class\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d584f327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Усреднённые AUC-ROC\n",
    "unique_labels, label_counts = np.unique(test_labels, return_counts=True)\n",
    "weights = label_counts[np.argsort(unique_labels)] / label_counts.sum()\n",
    "roc_scores = np.array(roc_scores)\n",
    "\n",
    "macro = roc_scores.mean()\n",
    "weighted = (roc_scores * weights).sum()\n",
    "\n",
    "print('Macro averaged AUC-ROC:', macro)\n",
    "print('Weighted averaged AUC-ROC:', weighted)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
